# Python-RA

_A ideia é estudar um pouco sobre as funcionalidades do github e de python neste projeto._

### Etapas do Projeto

Etapas que tenho em mente neste momento, podendo incluir outras depois ou dividir uma etapa se tiver muitos assuntos num mesmo tópico. (_6 e 7 provavelmente_)

- [x] 01 - Definição do escopo de estudo.
- [x] 02 - Entregáveis do projeto, como integrar os dados que serão obtidos neste projeto com a camada de visualização.
- [x] 03 - Definição do que será raspado, tanto na pasta raiz quanto nas reclamações individuais, capturando também réplicas, tréplicas, etc.
- [ ] 04 - Estudo das bibliotecas de scraping, entendendo melhores casos de uso de de cada uma.
- [ ] 05 - Estudo de github
- [ ] 06 - Identificar qual ou quais as melhores bibliotecas se adequariam a este projeto. (Entendendo que durante a fase de execução poderá ser necessário alterar e informar o motivo)
- [ ] 07 - Criar código base de extração.
- [ ] 08 - Criar código base do tratamento.
- [ ] 09 - Limpeza e otimização dos códigos, alterar loops por funções, etc.
- [ ] 10 - Modelagem de Dados.
- [ ] 11 - Parametrização da solução -> Diretório para salvar arquivos; Nome/Site da extração; Webdriver (se usarmos Selenium); Páginas a extrair ou Data; Condição adicional na base de tratamento, filtros adicionais, etc.
- [ ] 12 - Estudo de alternativas do projeto. "Como seria" se fosse utilizado as bibliotecas X ou Y. (mais casos de estudo)
- [ ] 13 - Como criar pacote da solução / Releases e estudar sobre como complicar em um executável.
- [ ] 14 - Elaborar uma documentação para este projeto, endereçando o que foi visto em cada etapa, sempre salvando fontes e links relevantes/alterativas, etc.
